{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9cc71a2",
   "metadata": {},
   "source": [
    "<font size=\"6\"><b>Mobile App Customer Segmentation</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b89b0e",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "This analysis aims to segment app users by their purchase behavior, affinity to technology, and personality traits to tailor promotional strategies that successfully reach each type of potential customer and drive engagement to the platform and its services.\n",
    "\n",
    "Five different segments were identified, with the App Value Leaders and Free App Enthusiasts having the most revenue potential, based on how active they are online and how prone they are to acquire paid features. \n",
    "\n",
    "Both of these groups are inclined to try new things and be up-to-date with technology, yet the main difference between them is that App Value Leaders would be more likely to spend on premium features, while Free App Enthusiasts should be approached through discounts and deals.\n",
    "\n",
    "The platforms with the most traffic amongst the potential customer groups are Facebook and YouTube. Therefore, social media campaigns should be prioritized through these two channels to reach larger audiences and optimize resources.\n",
    "\n",
    "Carrying out a new survey considering newer social media platforms, such as Instagram and TikTok, could prove useful to better tailor the strategies and consider new behavioral trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36907365",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "## Importing the data\n",
    "\n",
    "The first step in modeling is preparing the data. For better readability, it is also useful to rename the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714341a2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import standard packages\n",
    "import numpy             as np                          # mathematical essentials\n",
    "import pandas            as pd                          # data science essentials\n",
    "import matplotlib.pyplot as plt                         # fundamental data visualization\n",
    "import seaborn           as sns                         # enhanced visualization\n",
    "\n",
    "# import machine learning packages\n",
    "from sklearn.preprocessing   import StandardScaler      # standard scaler\n",
    "from sklearn.decomposition   import PCA                 # pca\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage # dendrograms\n",
    "from sklearn.cluster         import KMeans              # k-means clustering\n",
    "\n",
    "# new column names\n",
    "cols = ['Case_ID', 'age', 'has_iPhone', 'has_iPod', 'has_Android', 'has_Blackberry', 'has_Nokia', 'has_Windows', 'has_HP',\n",
    "       'has_Tablet', 'has_other_smartphone', 'has_no_device', 'app_music', 'app_tv_checkin', 'app_entertainment',\n",
    "       'app_tv_show', 'app_gaming', 'app_social', 'app_general_news', 'app_shopping', 'app_specific_news', 'app_other',\n",
    "       'app_none', 'nr_apps', 'free_apps_pct', 'facebook_frq', 'twitter_frq', 'myspace_frq', 'pandora_frq', 'vevo_frq',\n",
    "       'youtube_frq', 'aol_frq', 'lastfm_frq', 'yahoo_frq', 'imdb_frq', 'linkedin_frq', 'netflix_frq', '24_tech_dev',\n",
    "       '24_tech_advise', '24_purchase', '24_too_much_tech', '24_control_life', '24_save_time', '24_music', '24_tv_shows',\n",
    "       '24_information', '24_networking', '24_contact', '24_avoid_contact', '25_opinion_leader', '25_stand_out', \n",
    "       '25_offer_advice', '25_decision_making', '25_new_things', '25_responsibility', '25_control', '25_risk_taker',\n",
    "       '25_creative', '25_optimistic', '25_active', '25_stretched','26_attracted_luxury', '26_discount', '26_enjoy_shopping', \n",
    "        '26_package_deals', '26_online_shopping', '26_buy_designer', '26_love_apps', '26_cool_apps', '26_show_off',\n",
    "       '26_children_impact', '26_pay_features', '26_spend_money', '26_hot_not', '26_reflect_style', '26_impulse_purchase',\n",
    "       '26_entertainment_source', 'level_education', 'marital_status', 'children_none', 'children_under_6', 'children_6_12',\n",
    "        'children_13_17', 'children_above_18', 'race', 'hispanic', 'income', 'gender']\n",
    "\n",
    "# loading data with our column names\n",
    "survey_df = pd.read_excel(io        = 'Mobile_App_Survey_Data.xlsx',\n",
    "                          names     = cols,\n",
    "                          index_col = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d83d5",
   "metadata": {},
   "source": [
    "## Merging Categories\n",
    "\n",
    "Demographic questions results are merged based on the customers' preferred app store, the kind of applications they use and, how frequently they do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column for store usage\n",
    "survey_df['Apple AppStore'] = np.where(survey_df['has_iPhone'] + survey_df['has_iPod'] > 0 , 1, 0)\n",
    "survey_df['Android PlayStore'] = np.where(survey_df['has_Android'] + survey_df['has_Nokia'] + survey_df['has_HP']  + survey_df['has_Blackberry'] > 0 , 1, 0)\n",
    "survey_df['Windows Store'] = np.where(survey_df['has_Windows'] > 0 , 1, 0)\n",
    "\n",
    "# group similar types of apps together\n",
    "survey_df['news'] = np.where(survey_df['app_general_news']+survey_df['app_specific_news'] > 0 , 1, 0)\n",
    "survey_df['entertainment'] = np.where(survey_df['app_tv_checkin']+survey_df['app_entertainment']+survey_df['app_tv_show'] > 0 , 1, 0)\n",
    "\n",
    "# App usage --> 1 and 2 are users, 3 and 4 rarely use the app\n",
    "survey_df['Uses_Facebook'] = np.where(survey_df['facebook_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_Twitter'] = np.where(survey_df['twitter_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_Pandora'] = np.where(survey_df['pandora_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_Vevo'] = np.where(survey_df['vevo_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_Youtube'] = np.where(survey_df['youtube_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_AOL'] = np.where(survey_df['aol_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_LastFM'] = np.where(survey_df['lastfm_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_yahoo'] = np.where(survey_df['yahoo_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_imdb'] = np.where(survey_df['imdb_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_LinkedIn'] = np.where(survey_df['linkedin_frq'] <= 2 , 1, 0)\n",
    "survey_df['Uses_netflix'] = np.where(survey_df['netflix_frq'] <= 2 , 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f5820b",
   "metadata": {},
   "source": [
    "## Defining psychometric columns\n",
    "\n",
    "For later use, group the columns into three main groups: technical, personal, and purchase behavior type of questions:\n",
    "- Technical: Related to people's relationship with technology and whether it influences their daily life.\n",
    "- Personal: Traits associated with leadership and approaches to risk.\n",
    "- Purchase behavior: Related to the thought process behind their shopping behavior and what criteria they set in place when acquiring new technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions about technology --> usage \n",
    "technical_usage = ['24_tech_dev', '24_tech_advise', \n",
    "                   '24_purchase', '24_too_much_tech', '24_control_life', '24_save_time', '24_music', '24_tv_shows', \n",
    "                   '24_information', '24_networking', '24_contact', '24_avoid_contact']\n",
    "\n",
    "# questions about leadership/ if a person is adventurous --> personal features\n",
    "personal_features = ['25_opinion_leader', '25_stand_out', '25_offer_advice', '25_decision_making', '25_new_things', \n",
    "                    '25_responsibility', '25_control', '25_risk_taker', '25_creative', '25_optimistic', '25_active', \n",
    "                    '25_stretched']\n",
    "\n",
    "# questions if a person is attracted to money, the newest trends, apps --> purchase behaviour\n",
    "purchase_behaviour = ['free_apps_pct', '26_attracted_luxury', '26_discount', '26_enjoy_shopping', '26_package_deals', \n",
    "                     '26_online_shopping', '26_buy_designer', '26_love_apps', '26_cool_apps', '26_show_off', \n",
    "                     '26_children_impact', '26_pay_features', '26_spend_money', '26_hot_not', '26_reflect_style', \n",
    "                     '26_impulse_purchase', '26_entertainment_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ce026d",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "\n",
    "### Scaling Rows\n",
    "An essential step in using PCA is scaling the data. First, the rows have to be scaled. That step is needed, as there are several types of people in surveys:\n",
    "\n",
    "1.\tPeople that tend to go to the extremes: Mainly putting strongly agree or disagree, rarely being neutral in the middle.\n",
    "2.\tPeople that avoid extremes: Mainly being neutral in the middle and rarely have a strong standing.\n",
    "\n",
    "To compare both of these types fairly, scaling is needed.\n",
    "\n",
    "### Scaling Columns\n",
    "The columns have to be scaled for the PCA model as a second step. Columns need to be normalized as PCA maximizes the variance by projecting the original data into directions.\n",
    "\n",
    "For both of these steps, a function is written. In addition, a function for scaling both rows and columns at once is provided for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14939e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_columns(df):\n",
    "    \"\"\"\n",
    "    Standardizes a dataset (mean = 0, variance = 1). Returns a new DataFrame\n",
    "    with scaled columns. Requires sklearn.preprocessing.StandardScaler().\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"\n",
    "\n",
    "    # INSTANTIATING a StandardScaler() object\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # fitting the scaler with the data\n",
    "    scaler.fit(df)\n",
    "\n",
    "    # transforming our data after fit\n",
    "    x_scaled = scaler.transform(df)\n",
    "   \n",
    "    # converting scaled data into a DataFrame\n",
    "    new_df = pd.DataFrame(x_scaled)\n",
    "\n",
    "    # reattaching column names\n",
    "    new_df.columns = df.columns\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def scaler_rows(df):\n",
    "    \"\"\"\n",
    "    Standardizes the rows of a dataset (mean = 0, variance = 1). Returns a new DataFrame\n",
    "    with scaled rows. Requires sklearn.preprocessing.StandardScaler().\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transpose the DataFrame, scale and Transpose back\n",
    "    df_scaled = scaler_columns(df.T).T\n",
    "    \n",
    "    # reattaching column names\n",
    "    df_scaled.columns = df.columns\n",
    "    \n",
    "    return df_scaled\n",
    "    \n",
    "def scaler(df):\n",
    "    \"\"\"\n",
    "    Standardizes the rows and columns of a dataset (mean = 0, variance = 1). \n",
    "    Returns a new DataFrame with scaled rows and columns. \n",
    "    Requires sklearn.preprocessing.StandardScaler().\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df     | DataFrame to be used for scaling\n",
    "    \"\"\"    \n",
    "    \n",
    "    # scale the rows\n",
    "    df_scaled_rows = scaler_rows(df)\n",
    "    \n",
    "    # scale the columns\n",
    "    df_scaled_cols = scaler_columns(df_scaled_rows)\n",
    "    \n",
    "    return df_scaled_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691d476",
   "metadata": {},
   "source": [
    "## Running the PCA-model\n",
    "\n",
    "### Providing a function to run PCA\n",
    "\n",
    "Principal Component Analysis is run and analyzed to reduce the number of features. PCA is a dimensionality-reduction method that transforms large datasets into smaller ones containing most of the information.\n",
    "\n",
    "Scree plots are used to decide how many columns of the PCA model to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0587e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the elbow plot\n",
    "def scree_plot(pca_object, export = False):\n",
    "    \"\"\"\n",
    "    Visualizes a scree plot from a pca object.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    pca_object | A fitted pca object\n",
    "    export     | Set to True if you would like to save the scree plot to the\n",
    "               | current working directory (default: False)\n",
    "    \"\"\"\n",
    "\n",
    "    # setting plot size\n",
    "    fig, ax = plt.subplots(figsize=(20, 16))\n",
    "    features = range(pca_object.n_components_)\n",
    "\n",
    "    # developing a scree plot\n",
    "    plt.plot(features,\n",
    "             pca_object.explained_variance_ratio_,\n",
    "             linewidth = 2,\n",
    "             marker = 'o',\n",
    "             markersize = 10,\n",
    "             markeredgecolor = 'black',\n",
    "             markerfacecolor = 'grey')\n",
    "\n",
    "    # setting more plot options\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('PCA feature')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.xticks(features)\n",
    "\n",
    "    if export == True:   \n",
    "        # exporting the plot\n",
    "        plt.savefig('./__analysis_images/top_customers_correlation_scree_plot.png')\n",
    "        \n",
    "    # displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca(df, check_factors = False, name = 'test.xlsx', n_components = None,  show_plot = False):\n",
    "    \"\"\"\n",
    "    Runs a PCA on a DataFrame. The DataFrame should be scaled before. The function\n",
    "    outputs an Excel-file with the PCA-results to analyze and shows elbow\n",
    "    plot if chosen. The function returns the factor loaded dataframe with the\n",
    "    found pca-clusters in columns and original columns in rows \n",
    "    (if check_factors == True) or the pca dataframe with the pca-values for \n",
    "    each row of the original DataFrame (if check_factors == False).\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df            | DataFrame to be used for PCA\n",
    "    check_factors | Decide, whether factors transposed or original DataFrme should\n",
    "                    be returned\n",
    "    name          | Name, which the Excel-file should get\n",
    "    n_components  | Number of components to consider for PCA\n",
    "    show_plot     | Defines, if the elbow plot should be shown. Is true by default.\n",
    "    \"\"\"\n",
    "    \n",
    "    # INSTANTIATING a PCA object with no limit to principal components\n",
    "    pca = PCA(n_components = n_components,\n",
    "              random_state = 219)\n",
    "\n",
    "    # FITTING and TRANSFORMING the scaled data\n",
    "    pca_fit = pca.fit_transform(df)\n",
    "    \n",
    "    if check_factors:\n",
    "        # calling the scree_plot function\n",
    "        if show_plot:\n",
    "            scree_plot(pca_object = pca)\n",
    "\n",
    "\n",
    "        # transposing pca components\n",
    "        factor_loadings_df = pd.DataFrame(np.transpose(pca.components_.round(decimals = 2)))\n",
    "\n",
    "        # naming rows as original features\n",
    "        factor_loadings_df = factor_loadings_df.set_index(df.columns)\n",
    "\n",
    "        # saving to Excel\n",
    "        factor_loadings_df.to_excel(f'{name}.xlsx')\n",
    "    else: \n",
    "        factor_loadings_df = pd.DataFrame(pca_fit)\n",
    "\n",
    "    return factor_loadings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d43d4",
   "metadata": {},
   "source": [
    "### Running PCA on the survey dataset\n",
    "\n",
    "To run the PCA, the following steps are needed:\n",
    "1.\tCreate DataFrames for technical person, and purchase behavior features.\n",
    "2.\tRun PCA for every feature. Therefore, these steps are needed:\n",
    "    - Scale the DataFrame.\n",
    "    - Run PCA and set n_components to None to create a model that explains all the variance. Plot the features in a scree plot and develop a reasonable number of features. To check the connection between PCA components and the original columns, group names for each PCA component are defined, and check_factors have been set to True.\n",
    "1.\tCheck the scree plot and look for the elbow. In the survey, taking three components for each PCA model is reasonable.\n",
    "2.\tGo into the Excel files and come up with names fitting the PCA columns.\n",
    "3.\tCreate a DataFrame containing all the columns of the three PCA models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a61acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df's for the features\n",
    "df_technical = survey_df[technical_usage]\n",
    "df_personal = survey_df[personal_features]\n",
    "df_purchase = survey_df[purchase_behaviour]\n",
    "# all_dfs = [df_technical, df_personal, df_purchase]\n",
    "\n",
    "# for df in all_dfs:\n",
    "    \n",
    "#     # create the name for each dataframe\n",
    "#     # from: https://stackoverflow.com/questions/31727333/get-the-name-of-a-pandas-dataframe\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "    \n",
    "#     # scale the data\n",
    "#     scaled_df = scaler(df)\n",
    "    \n",
    "#     # run PCA  \n",
    "#     run_pca(df            = scaled_df, \n",
    "#             check_factors = True, \n",
    "#             name          = name, \n",
    "#             n_components  = None,  \n",
    "#             show_plot     = True)\n",
    "\n",
    "\n",
    "# get factors and name for features for personal features\n",
    "scaled_personal = scaler(df_personal) \n",
    "factor_loadings_personal = run_pca(df = scaled_personal, n_components = 3)\n",
    "personal_cols = ['Followers',                 # followers, easily influenced by others\n",
    "                 'Calculated Risk Takers',    # conservative inactive pessimists\n",
    "                 'Controlling Leaders']       # submissive non-creatives\n",
    "factor_loadings_personal.columns = personal_cols\n",
    "\n",
    "# get factors and name for features for technical features\n",
    "scaled_tech = scaler(df_technical)\n",
    "factor_loadings_technical = run_pca(df = scaled_tech, n_components = 3)\n",
    "tech_cols = ['Offliners',               # too much info and tech out there, prefer offline contact\n",
    "             'Frugal Onliners',         # always online, don't care about having the latest\n",
    "             'Relaxed and Empowered']   # chill, up-to-date, with control over their lives\n",
    "factor_loadings_technical.columns = tech_cols\n",
    "\n",
    "# get factors and name for features for purchase features\n",
    "scaled_purchase = scaler(df_purchase)\n",
    "factor_loadings_purchase = run_pca(df = scaled_purchase, n_components = 3)\n",
    "purchase_cols = ['Cheap App Lovers',       # Customer looking for best features in free apps   \n",
    "                 'Spending App Lovers',    # attracted to the what's hot, and the best, sometimes regardless of price\n",
    "                 'App Acquisition Planners']  # plan their purchases according to their needs\n",
    "factor_loadings_purchase.columns = purchase_cols\n",
    "\n",
    "# create DataFrame with all PCA features\n",
    "factors_df = pd.concat([factor_loadings_personal, factor_loadings_technical, factor_loadings_purchase], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020510b",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "The next step of data preparation is to create clusters for the consumers based on PCA findings with K-Means-Clustering. Because this algorithm is based on distance and variance, the data is scaled again before being grouped. \n",
    "\n",
    "After analyzing the dendrogram, five clusters are defined:\n",
    "\n",
    "~~~\n",
    "Cluster\n",
    "0          309\n",
    "1          326\n",
    "2          287\n",
    "3          349\n",
    "4          281\n",
    "~~~\n",
    "\n",
    "The function below allows setting the check_centers parameter to True to create an Excel file with the PCA columns and the newly created clusters to evaluate and label each cluster as follows:\n",
    "- 0 - Free App Enthusiasts: They are up to date on technology, like learning new things, and are always online. Even though they love using several apps, they usually avoid paying but cannot resist a bargain.\n",
    "- 1 - App Value Leaders: They are knowledgeable in their field and easily influence others. They like apps, are credible, and can be targeted through respectable social media influencers.\n",
    "- 2 - Economical and Efficient: The economic buyer is cost-effective when acquiring new apps and looks for tools that add value to their everyday lives and maximize their benefits and efficiency.\n",
    "- 3 - Carefree App Followers: They go with the flow, do not spend much time online and are impulsive buyers. They are attracted to paid features that add value to their lives without detracting from their in-person interactions.\n",
    "- 4 - Indifferent Shopper: They are not desperate to hop on the next trend when it comes to apps. They are often satisfied with products that they already have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be662290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering(df, n_clusters = 8, dendogram = False, check_centers = False):\n",
    "    \"\"\"\n",
    "    Runs a Clustering on a DataFrame and scales before doing so. \n",
    "    A dendogram for the clustering is shown, if chosen in the parameter dendogram.\n",
    "    Returns a DataFrame with the clusters for each row\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df            | DataFrame to be used for clustering\n",
    "    n_clusters    | Number of clusters to be created, by default it is 8,\n",
    "                    the default value of sklearn.cluster.KMeans\n",
    "    dendogram     | Whether or not a dendogram of the clustering should be shown\n",
    "    check_centers | Whether or not to create an Excel-file to look into the \n",
    "                    clusters and come up with names\n",
    "    \"\"\"    \n",
    "\n",
    "    # scale the df\n",
    "    pca_scaled = scaler_columns(df)\n",
    "    \n",
    "    if dendogram:\n",
    "        # grouping data based on Ward distance\n",
    "        standard_mergings_ward = linkage(y                = pca_scaled,\n",
    "                                         method           = 'ward',\n",
    "                                         optimal_ordering = True)\n",
    "\n",
    "        # setting plot size\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "        # developing a dendrogram\n",
    "        dendrogram(Z              = standard_mergings_ward,\n",
    "                   leaf_rotation  = 90,\n",
    "                   leaf_font_size = 6)\n",
    "\n",
    "        # rendering the plot\n",
    "        plt.show()\n",
    "        \n",
    "    # INSTANTIATING a k-Means object with n clusters\n",
    "    k_clustering = KMeans(n_clusters   = n_clusters,\n",
    "                          random_state = 219)\n",
    "\n",
    "    # fitting the object to the data\n",
    "    k_clustering.fit(pca_scaled)\n",
    "    \n",
    "    \n",
    "    # checking the centroids\n",
    "    if check_centers:\n",
    "        # storing cluster centers\n",
    "        centroids = k_clustering.cluster_centers_\n",
    "\n",
    "        # converting cluster centers into a DataFrame\n",
    "        centroids_df = pd.DataFrame(centroids).round(2)\n",
    "\n",
    "        # renaming principal components\n",
    "        centroids_df.columns = pca_scaled.columns\n",
    "        \n",
    "        # send to excel \n",
    "        centroids_df.to_excel('clusters.xlsx')\n",
    "\n",
    "    # converting the clusters to a DataFrame giving each row a cluster\n",
    "    kmeans_df = pd.DataFrame({'Cluster': k_clustering.labels_})\n",
    "    \n",
    "    return kmeans_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e9e15",
   "metadata": {},
   "source": [
    "## Translating Columns\n",
    "\n",
    "It is recommended to rename the most critical columns. Additionally, a pivot-version for the used apps and stores is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84126596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clusters\n",
    "df_cluster = run_clustering(factors_df, n_clusters = 5)\n",
    "\n",
    "# replace by cluster name \n",
    "cluster_names = {0 : 'Free App Enthusiasts',\n",
    "                 1 : 'App Value Leaders',\n",
    "                 2 : 'Economical and Efficient',\n",
    "                 3 : 'Carefree App Followers',\n",
    "                 4 : 'Indifferent Shoppers'}\n",
    "\n",
    "df_cluster = df_cluster['Cluster'].replace(cluster_names)\n",
    "\n",
    "# concatinating cluster memberships with principal components\n",
    "clst_pca_df = pd.concat([df_cluster,\n",
    "                        factors_df],\n",
    "                        axis = 1)\n",
    "\n",
    "# rename age by group names of age\n",
    "age_names = {1 : '1 - Gen Z',\n",
    "             2 : '1 - Gen Z',\n",
    "             3 : '2 - Millenials',\n",
    "             4 : '2 - Millenials',\n",
    "             5 : '2 - Millenials',\n",
    "             6 : '3 - Gen X',\n",
    "             7 : '3 - Gen X',\n",
    "             8 : '3 - Gen X',\n",
    "             9 : '4 - Boomers',\n",
    "            10 : '4 - Boomers',\n",
    "            11 : '4 - Boomers'}\n",
    "\n",
    "survey_df['age'] = survey_df['age'].replace(age_names)\n",
    "\n",
    "# translate age by groups of income\n",
    "salary_names = {1 : '1 - Under 30k',\n",
    "                2 : '1 - Under 30k',\n",
    "                3 : '1 - Under 30k',\n",
    "                4 : '1 - Under 30k',\n",
    "                5 : '2 - 30k - 50k',\n",
    "                6 : '2 - 30k - 50k',\n",
    "                7 : '3 - 50k - 70k',\n",
    "                8 : '3 - 50k - 70k',\n",
    "                9 : '4 - 70k - 100k',\n",
    "               10 : '4 - 70k - 100k',\n",
    "               11 : '4 - 70k - 100k',\n",
    "               12 : '5 - Over 100k',\n",
    "               13 : '5 - Over 100k',\n",
    "               14 : '5 - Over 100k'}\n",
    "\n",
    "survey_df['income'] = survey_df['income'].replace(salary_names)\n",
    "\n",
    "\n",
    "# concatenating demographic information with pca-clusters\n",
    "final_pca_clust_df = pd.concat([survey_df.loc[ : , ['age', 'income', 'Apple AppStore', 'Android PlayStore', \n",
    "                                                    'Windows Store', 'has_Tablet', 'Uses_Facebook', \n",
    "                                                    'Uses_Twitter', 'Uses_Pandora', 'Uses_Vevo', 'Uses_Youtube', \n",
    "                                                    'Uses_AOL', 'Uses_LastFM', 'Uses_yahoo', 'Uses_imdb', \n",
    "                                                    'Uses_LinkedIn', 'Uses_netflix'\n",
    "                                                   ]],\n",
    "                                  clst_pca_df.round(decimals = 2)],\n",
    "                                  axis = 1)\n",
    "\n",
    "data_df = final_pca_clust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03530118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the store and create new DataFrame, only keep the rows where user uses the store\n",
    "store_df = data_df[['Apple AppStore', 'Android PlayStore',  'Windows Store', 'has_Tablet', 'Cluster', 'Followers', \n",
    "                    'Calculated Risk Takers', 'Controlling Leaders', 'Offliners', 'Cheap App Lovers', 'Spending App Lovers',\n",
    "                   'App Acquisition Planners']]\n",
    "\n",
    "store_df = store_df.melt(id_vars=['Cluster', 'Followers', 'Calculated Risk Takers',\n",
    "                                'Controlling Leaders', 'Offliners', 'Cheap App Lovers', 'Spending App Lovers',\n",
    "                               'App Acquisition Planners'],\n",
    "                                var_name='Store', value_name='Uses_Store')\n",
    "\n",
    "store_df = store_df.loc[:, :][store_df.loc[:, 'Uses_Store'] == 1]\n",
    "\n",
    "# pivot the app usage and create new DataFrame, only keep the rows where user uses the app\n",
    "app_usage_df = data_df[['Uses_Facebook', 'Uses_Twitter', 'Uses_Pandora', 'Uses_Vevo', 'Uses_Youtube', \n",
    "                        'Uses_AOL', 'Uses_LastFM', 'Uses_yahoo', 'Uses_imdb', 'Uses_LinkedIn', \n",
    "                        'Uses_netflix', 'Cluster', 'Followers',  'Calculated Risk Takers', \n",
    "                        'Controlling Leaders', 'Offliners','Cheap App Lovers', 'Spending App Lovers',\n",
    "                           'App Acquisition Planners']]\n",
    "\n",
    "app_usage_df = app_usage_df.melt(id_vars=['Cluster', 'Followers', 'Calculated Risk Takers',\n",
    "                                'Controlling Leaders', 'Offliners', 'Cheap App Lovers', 'Spending App Lovers',\n",
    "                               'App Acquisition Planners'],\n",
    "                                var_name='App', value_name='Uses_App')\n",
    "\n",
    "app_usage_df = app_usage_df.loc[:, :][app_usage_df.loc[:, 'Uses_App'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d7a72",
   "metadata": {},
   "source": [
    "# Strategies for clusters\n",
    "\n",
    "Now that the clusters have been identified, each type of customer will be approached as follows:\n",
    "\n",
    "Free App Enthusiasts:\n",
    "- Being one of the two most important groups in revenue potential, the apps offered to this cluster should have two versions: free and premium.\n",
    "- Potential customers should be approached with free initial trials and new user deals, along with a referral system that can award them with points or credits that can be used towards premium features.\n",
    "- Promotion should be carried out through the most popular social media channels within this group.\n",
    "- This group should be offered apps that allow them to connect with others and express themselves, with customizable features, and where they can gather a following.\n",
    "\n",
    "App Value Leaders:\n",
    "- As they are the other leading group with the most revenue potential, the content and features offered on the application ought to add value to their daily lives, which will increase their usage of the services and even create the possibility of them being a bridge to bring new customers on board.\n",
    "- Influencers dominate social media platforms. However, since the people belonging to this cluster are leaders themselves, they should be targeted through collaboration with aspirational leaders that drive engagement in the app and be offered the opportunity to connect and create.\n",
    "- For this, they should be offered a creator back-end so that the content they generate is of higher quality than a regular user. This will allow them to build rapport with their following and garner attention to premium features for users on other clusters.\n",
    "- Converting application users to loyal users by offering rewards and redeemable points that they can accumulate over time for engagement and referrals, and later be converted into discounts packages and access to premium features.\n",
    "- Engagement campaigns should be based on current affairs and run on work-related social media platforms and electronic news publications and blogs, driving more traffic of this specific type of customer to the app.\n",
    "\n",
    "Economical and Efficient:\n",
    "- This customer does not shy away from paid apps but will usually plan their purchase aiming to obtain the most benefit, which is why they should be approached through free trials that allow them to assess whether the app is relevant enough for them to commit financially.\n",
    "- Since they are more hands-on and concerned with how the app brings utility to their lifestyle, they should be offered apps that enhance their relationship with health, fitness, finances, and even simple daily tasks.\n",
    "- Other strategies that could prove effective are new user deals or feature packages, with bundles for different prices that will allow them to decide which best fit their needs and budget.\n",
    "\n",
    "Carefree App Followers:\n",
    "- This cluster should be targeted through in-person events or through sponsorships of large-scale events in which they can physically see and retain the brand logo and primary information.\n",
    "- One-day offers could be a good idea since they are somewhat impulsive buyers, and these deals being promoted by influencers of their respective age groups could prove to be more effective.\n",
    "- Online advertising should be done through news apps and websites, as well as blogs or LinkedIn.\n",
    "\n",
    "Indifferent Shoppers:\n",
    "- This type of customer should be approached through emotional targeting. Since they do not spend much time online, campaigns should have a long-lasting and impactful message.\n",
    "- Since they do not follow trends and feel comfortable with what they already have, another practical approach would be explicitly mentioning the app's benefits to their daily lives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11203e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_barplot(df, col_name, title):\n",
    "    \"\"\"\n",
    "    Out of given DataFrame, the function returns a boxplot with the col_name on\n",
    "    the x-axis and the frequency of each value on the y-axis. \n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    df            | DataFrame to be used for plotting\n",
    "    col_name      | Column which should be shown\n",
    "    title         | Title to show on the Graph\n",
    "    \"\"\"\n",
    "    \n",
    "    # create DataFrame for free app enthusiasts and count frequency\n",
    "    app_ent_df = df.loc[:, [col_name]][df.loc[:, 'Cluster'] == 'Free App Enthusiasts'].value_counts().rename_axis(col_name).to_frame('Freq')\n",
    "    app_ent_df.reset_index(level=0, inplace=True)\n",
    "    app_ent_df['Cluster'] = 'Free App Enthusiasts'\n",
    "\n",
    "    # create DataFrame for app value leaders and count frequency\n",
    "    app_leaders_df = df.loc[:, [col_name]][df.loc[:, 'Cluster'] == 'App Value Leaders'].value_counts().rename_axis(col_name).to_frame('Freq')\n",
    "    app_leaders_df.reset_index(level=0, inplace=True)\n",
    "    app_leaders_df['Cluster'] = 'App Value Leaders'\n",
    "    \n",
    "    # create DataFrame for economicals and count frequency\n",
    "    eco_df = df.loc[:, [col_name]][df.loc[:, 'Cluster'] == 'Economical and Efficient'].value_counts().rename_axis(col_name).to_frame('Freq')\n",
    "    eco_df.reset_index(level=0, inplace=True)\n",
    "    eco_df['Cluster'] = 'Economical and Efficient'\n",
    "    \n",
    "    # create DataFrame for carefree app followers and count frequency\n",
    "    carefree_df = df.loc[:, [col_name]][df.loc[:, 'Cluster'] == 'Carefree App Followers'].value_counts().rename_axis(col_name).to_frame('Freq')\n",
    "    carefree_df.reset_index(level=0, inplace=True)\n",
    "    carefree_df['Cluster'] = 'Carefree App Followers'\n",
    "    \n",
    "    # create DataFrame for free app indifferent shoppers and count frequency\n",
    "    shoppers_df = df.loc[:, [col_name]][df.loc[:, 'Cluster'] == 'Indifferent Shoppers'].value_counts().rename_axis(col_name).to_frame('Freq')\n",
    "    shoppers_df.reset_index(level=0, inplace=True)\n",
    "    shoppers_df['Cluster'] = 'Indifferent Shoppers'\n",
    "    \n",
    "    # concatenate all into one DataFrame\n",
    "    final_df = app_leaders_df.append([app_ent_df, eco_df, carefree_df, shoppers_df])\n",
    "    final_df = final_df.sort_values(col_name)\n",
    "    \n",
    "    # create boxplot \n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    # color palette for the chart\n",
    "    pal = ['navy', 'cornflowerblue', 'lightsteelblue', 'dimgray', 'lightgray']\n",
    "    \n",
    "    # boxplot\n",
    "    sns.barplot(x= col_name, y='Freq', hue='Cluster', data=final_df, palette=pal)\n",
    "    \n",
    "    # rotate x label\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    # get rid of axis labels\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlabel('')\n",
    "    \n",
    "    # create title\n",
    "    ax.set_title(title, size=18)\n",
    "\n",
    "    # show plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b98df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show app usage by cluster\n",
    "show_barplot(app_usage_df, 'App', 'App Usage by Cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a045ef",
   "metadata": {},
   "source": [
    "Social media campaigns should be tailored to the App Value Leaders and Free App Enthusiasts, given that they are the ones that spend the most time online and could be prone to use and spread the word about the app the most. Nonetheless, because Facebook and YouTube are the leading platforms used across all the clusters, these advertising efforts could also drive potential customers from the other groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec1b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show income distribution by cluster\n",
    "show_barplot(data_df, 'income', 'Income by Cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556d831",
   "metadata": {},
   "source": [
    "App Value Leaders are in the high-income bracket and are often attracted to premium features which is why they should be offered paid apps or in-app purchase options.\n",
    "\n",
    "Free App Enthusiasts have an average income lower than $50K a year, which validates the approach through free apps with premium features that they can later purchase from within the app with redeemable credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d1bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show store preference by cluster\n",
    "show_barplot(store_df, 'Store', 'Store by Cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6864b7f",
   "metadata": {},
   "source": [
    "The budget should prioritize the development and maintenance of the apps offered mainly through the Apple AppStore and the Google PlayStore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0369850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show age distribution by cluster\n",
    "show_barplot(data_df, 'age', 'Age by Cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db6911",
   "metadata": {},
   "source": [
    "Millennials are the most relevant age group, and the top two social media platforms used by all clusters are Facebook and YouTube. Hence, Millennial influencers should be used to reach other age groups, as they could also become aspirational figures for Gen Z prospects.\n",
    "\n",
    "Further, two influencers' profiles could be approached for the social media campaigns: opinion leaders and content creators. The former could prove helpful to reach quality content-seeking clusters such as the App Value Leaders, while the latter could be more appropriate for Free App Enthusiasts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
